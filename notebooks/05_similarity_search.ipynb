{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ae8d6b",
   "metadata": {},
   "source": [
    "# 05. Similarity Search with FAISS\n",
    "\n",
    "This notebook brings everything together to build a similarity search engine using FAISS. We will:\n",
    "- Load the final dataset with multimodal embeddings.\n",
    "- Prepare the text and image embeddings and fuse them into a single vector for each item.\n",
    "- Build a FAISS index for efficient similarity search.\n",
    "- Perform a search using an existing item as a query.\n",
    "- Perform a search using a text query.\n",
    "- Create a simple Gradio interface to demonstrate the search functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2566fb",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d7a288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading data from c:\\Users\\minhk\\OneDrive\\Documents\\HCMUTSUB\\DACN\\reviews_with_img_text_emb_CDs_and_Vinyl.parquet...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Following columns were requested but are not available: {'title', 'image_url'}.\nAll requested columns: ['parent_asin', 'title', 'clip_img_emb', 'image_url']\nAvailable columns: ['asin', 'parent_asin', 'user_id', 'rating', 'title_x', 'text', 'timestamp', 'helpful_vote', 'verified_purchase', 'images_x', 'main_category', 'title_y', 'average_rating', 'rating_number', 'features', 'description', 'price', 'categories', 'store', 'img_url', 'clip_img_emb', 'has_img_emb', 'review_text', 'meta_text', 'review_text_emb', 'meta_text_emb', 'text_emb', 'images_y.hi_res', 'images_y.large', 'images_y.thumb', 'images_y.variant']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# To save memory, load only the columns we absolutely need\u001b[39;00m\n\u001b[32m     38\u001b[39m columns_to_load = [\u001b[33m'\u001b[39m\u001b[33mparent_asin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mclip_img_emb\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mimage_url\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m df_full = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFULL_DATA_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfastparquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Create a copy to avoid fragmentation issues and ensure contiguous memory\u001b[39;00m\n\u001b[32m     42\u001b[39m df = df_full.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:405\u001b[39m, in \u001b[36mFastParquetImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    404\u001b[39m     parquet_file = \u001b[38;5;28mself\u001b[39m.api.ParquetFile(path, **parquet_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparquet_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastparquet\\api.py:745\u001b[39m, in \u001b[36mParquetFile.to_pandas\u001b[39m\u001b[34m(self, columns, categories, filters, index, row_filter, dtypes)\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index:\n\u001b[32m    744\u001b[39m     columns += [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m index \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns]\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m \u001b[43mcheck_column_names\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m row_filter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    747\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mand\u001b[39;00m row_filter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    748\u001b[39m         \u001b[38;5;66;03m# Rows are selected as per filters.\u001b[39;00m\n\u001b[32m    749\u001b[39m         \u001b[38;5;66;03m# TODO: special case when filter columns are also in output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastparquet\\util.py:132\u001b[39m, in \u001b[36mcheck_column_names\u001b[39m\u001b[34m(columns, *args)\u001b[39m\n\u001b[32m    130\u001b[39m missing = \u001b[38;5;28mset\u001b[39m(arg) - \u001b[38;5;28mset\u001b[39m(columns)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFollowing columns were requested but are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33mnot available: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33mAll requested columns: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    135\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33mAvailable columns: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    136\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m % (missing, arg, columns))\n",
      "\u001b[31mValueError\u001b[39m: Following columns were requested but are not available: {'title', 'image_url'}.\nAll requested columns: ['parent_asin', 'title', 'clip_img_emb', 'image_url']\nAvailable columns: ['asin', 'parent_asin', 'user_id', 'rating', 'title_x', 'text', 'timestamp', 'helpful_vote', 'verified_purchase', 'images_x', 'main_category', 'title_y', 'average_rating', 'rating_number', 'features', 'description', 'price', 'categories', 'store', 'img_url', 'clip_img_emb', 'has_img_emb', 'review_text', 'meta_text', 'review_text_emb', 'meta_text_emb', 'text_emb', 'images_y.hi_res', 'images_y.large', 'images_y.thumb', 'images_y.variant']"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import gradio as gr\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "from src.embedding_utils import get_text_model, prepare_multimodal_embeddings\n",
    "from src.faiss_utils import (\n",
    "    build_faiss_index, \n",
    "    search_faiss_index, \n",
    "    create_multimodal_query, \n",
    "    get_search_results,\n",
    "    save_faiss_index,\n",
    "    load_faiss_index\n",
    ")\n",
    "\n",
    "# --- Configuration ---\n",
    "CATEGORY = \"CDs_and_Vinyl\"\n",
    "DATA_DIR = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "FULL_DATA_FILE = os.path.join(DATA_DIR, f\"reviews_with_img_text_emb_{CATEGORY}.parquet\")\n",
    "FAISS_INDEX_FILE = os.path.join(DATA_DIR, f\"faiss_index_{CATEGORY}.bin\")\n",
    "ASIN_MAP_FILE = os.path.join(DATA_DIR, f\"asin_to_idx_{CATEGORY}.json\")\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load data\n",
    "print(f\"Loading data from {FULL_DATA_FILE}...\")\n",
    "# To save memory, load only the columns we absolutely need\n",
    "columns_to_load = ['parent_asin', 'title', 'clip_img_emb', 'image_url']\n",
    "df_full = pd.read_parquet(FULL_DATA_FILE, columns=columns_to_load, engine='fastparquet')\n",
    "\n",
    "# Create a copy to avoid fragmentation issues and ensure contiguous memory\n",
    "df = df_full.copy()\n",
    "del df_full\n",
    "gc.collect() # Force garbage collection to free up memory\n",
    "\n",
    "# Ensure all embeddings are numpy arrays\n",
    "df['img_embedding'] = df['img_embedding'].apply(np.array)\n",
    "df['fused_embedding'] = df['fused_embedding'].apply(np.array)\n",
    "print(f\"Loaded {len(df)} rows.\")\n",
    "\n",
    "# Load text model\n",
    "text_model = get_text_model(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5e919",
   "metadata": {},
   "source": [
    "## 2. Prepare Embeddings and Build FAISS Index\n",
    "\n",
    "We'll extract the text and image embeddings, fuse them into a single multimodal embedding, and then build a FAISS index for fast similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c0b9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prepare_multimodal_embeddings() got an unexpected keyword argument 'text_embedding_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Prepare embeddings for FAISS\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m multimodal_embeddings, asin_to_idx = \u001b[43mprepare_multimodal_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_embedding_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfused_embedding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_embedding_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimg_embedding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Build and save FAISS index\u001b[39;00m\n\u001b[32m      9\u001b[39m faiss_index = build_faiss_index(multimodal_embeddings)\n",
      "\u001b[31mTypeError\u001b[39m: prepare_multimodal_embeddings() got an unexpected keyword argument 'text_embedding_col'"
     ]
    }
   ],
   "source": [
    "# Prepare embeddings for FAISS\n",
    "multimodal_embeddings, asin_to_idx = prepare_multimodal_embeddings(\n",
    "    df, \n",
    "    text_emb_col='fused_embedding', \n",
    "    img_emb_col='img_embedding'\n",
    ")\n",
    "\n",
    "# Build and save FAISS index\n",
    "faiss_index = build_faiss_index(multimodal_embeddings)\n",
    "save_faiss_index(faiss_index, asin_to_idx, FAISS_INDEX_FILE, ASIN_MAP_FILE)\n",
    "\n",
    "print(f\"FAISS index built and saved for category '{CATEGORY}'.\")\n",
    "print(f\"Index size: {faiss_index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448122a5",
   "metadata": {},
   "source": [
    "## 3. Search: Find Similar Items\n",
    "\n",
    "Let's test the index by picking a random item and finding its nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ce4550",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_faiss_index() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the index and mapping\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m faiss_index, asin_to_idx = \u001b[43mload_faiss_index\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfaiss_index_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCATEGORY\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.bin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43masin_to_idx_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCATEGORY\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m idx_to_asin = {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m asin_to_idx.items()}\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Pick a random item to use as a query\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: load_faiss_index() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Load the index and mapping\n",
    "faiss_index, asin_to_idx = load_faiss_index(f'faiss_index_{CATEGORY}.bin', f'asin_to_idx_{CATEGORY}.json')\n",
    "idx_to_asin = {v: k for k, v in asin_to_idx.items()}\n",
    "\n",
    "# Pick a random item to use as a query\n",
    "random_item_asin = df.sample(1)['parent_asin'].values[0]\n",
    "query_vector_index = asin_to_idx[random_item_asin]\n",
    "query_vector = faiss_index.reconstruct(query_vector_index)\n",
    "\n",
    "# Search for similar items\n",
    "distances, indices = search_faiss_index(faiss_index, query_vector.reshape(1, -1), k=5)\n",
    "\n",
    "# Display results\n",
    "print(f\"Query Item: {random_item_asin}\")\n",
    "get_search_results(distances, indices, df, idx_to_asin, random_item_asin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aeaaee",
   "metadata": {},
   "source": [
    "## 4. Search: Using a Text Query\n",
    "\n",
    "Now, let's perform a search using a natural language query. We'll generate a multimodal query vector from the text and use it to search the FAISS index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188319ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a text query\n",
    "text_query = \"a comfortable and stylish pair of shoes for everyday wear\"\n",
    "\n",
    "# Create a multimodal query vector\n",
    "query_vector = create_multimodal_query(text_query, text_model, device)\n",
    "\n",
    "# Search the index\n",
    "distances, indices = search_faiss_index(faiss_index, query_vector.reshape(1, -1), k=5)\n",
    "\n",
    "# Display results\n",
    "print(f\"Query Text: '{text_query}'\")\n",
    "get_search_results(distances, indices, df, idx_to_asin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b2b7a",
   "metadata": {},
   "source": [
    "## 5. Gradio Demo\n",
    "\n",
    "Finally, let's wrap our search functionality in a simple Gradio interface to create an interactive demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c796fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def search_and_display(query_text, search_by, query_item_asin=None):\n",
    "    if search_by == \"Text\":\n",
    "        query_vector = create_multimodal_query(query_text, text_model, device)\n",
    "    elif search_by == \"Item ASIN\":\n",
    "        if not query_item_asin or query_item_asin not in asin_to_idx:\n",
    "            return \"Invalid or missing ASIN.\", [], []\n",
    "        query_vector_index = asin_to_idx[query_item_asin]\n",
    "        query_vector = faiss_index.reconstruct(query_vector_index)\n",
    "    else:\n",
    "        return \"Invalid search type.\", [], []\n",
    "\n",
    "    distances, indices = search_faiss_index(faiss_index, query_vector.reshape(1, -1), k=5)\n",
    "    \n",
    "    results_df = get_search_results(distances, indices, df, idx_to_asin, query_item_asin if search_by == \"Item ASIN\" else None, return_df=True)\n",
    "    \n",
    "    if results_df.empty:\n",
    "        return \"No results found.\", [], []\n",
    "\n",
    "    # Prepare output for Gradio\n",
    "    output_text = results_df.to_string(index=False)\n",
    "    \n",
    "    image_gallery = []\n",
    "    for url in results_df['image_url']:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            image_gallery.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load image {url}: {e}\")\n",
    "            # Add a placeholder image if loading fails\n",
    "            image_gallery.append(Image.new('RGB', (100, 100), color = 'gray'))\n",
    "\n",
    "    return output_text, image_gallery\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Multimodal Product Search\")\n",
    "    gr.Markdown(f\"Search for products in the '{CATEGORY}' category.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            search_by = gr.Radio([\"Text\", \"Item ASIN\"], label=\"Search By\", value=\"Text\")\n",
    "            text_query_input = gr.Textbox(label=\"Text Query\", placeholder=\"e.g., a comfortable and stylish pair of shoes\")\n",
    "            asin_query_input = gr.Textbox(label=\"Item ASIN\", placeholder=\"e.g., B07816F551\")\n",
    "            search_button = gr.Button(\"Search\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            results_output = gr.Textbox(label=\"Search Results\", lines=10)\n",
    "            gallery_output = gr.Gallery(label=\"Product Images\", columns=5, height=\"auto\")\n",
    "\n",
    "    search_button.click(\n",
    "        fn=search_and_display,\n",
    "        inputs=[text_query_input, search_by, asin_query_input],\n",
    "        outputs=[results_output, gallery_output]\n",
    "    )\n",
    "\n",
    "demo.launch(debug=True, share=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
